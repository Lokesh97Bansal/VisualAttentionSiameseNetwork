{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHmeP1y6CT71"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import shutil # To unpack the dataset\n",
        "import glob # To get the list of directories'\n",
        "from PIL import Image, ImageChops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78fObHTmBa-t"
      },
      "source": [
        "# Unzipping the dataset\n",
        "# zip_path = \"/content/drive/MyDrive/IISc/sgv-real-localize-siamese.zip\"\n",
        "# shutil.unpack_archive(zip_path,\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XjqH-DsOP-p",
        "outputId": "929443ad-0d94-43d2-fa16-9403faeba090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2_iNPlXFrrA"
      },
      "source": [
        "def read_data(data_dir):\n",
        "    markers = []\n",
        "    nomarkers = []\n",
        "    nomarker_poss = []\n",
        "\n",
        "    for d in glob.glob(data_dir + '/*'):\n",
        "        marker_tensor = []\n",
        "        nomarker_tensor = []\n",
        "        nomarker_pos_tensor = []\n",
        "        \n",
        "        for fn in glob.glob(d + '/marker/*.jpg'):\n",
        "            img = Image.open(fn).convert('RGB')\n",
        "            img_tensor = tf.expand_dims(tf.convert_to_tensor(np.array(img)),0)#.unsqueeze(0)\n",
        "            marker_tensor.append(img_tensor)\n",
        "        \n",
        "        for fn in glob.glob(d + '/nonmarker/*.jpg'):\n",
        "            img = Image.open(fn).convert('RGB')\n",
        "            img_tensor = tf.expand_dims(tf.convert_to_tensor(np.array(img)),0)#.unsqueeze(0)\n",
        "            nomarker_tensor.append(img_tensor)\n",
        "            # print('Image_name',fn)\n",
        "            xstr, ystr = fn.split('_')[-2:]\n",
        "            # print('xstr',xstr)\n",
        "            # print('ystr',ystr)\n",
        "            x, y = int(xstr)/150.0, int(ystr[:-4])/150.0\n",
        "            # print('x',x)\n",
        "            # print('y',y)\n",
        "            nomarker_pos_tensor.append([x, y])\n",
        "        \n",
        "        marker_tensor = tf.concat(marker_tensor, 0)\n",
        "        nomarker_tensor = tf.concat(nomarker_tensor, 0)\n",
        "        nomarker_pos_tensor = tf.convert_to_tensor(np.array(nomarker_pos_tensor))\n",
        "\n",
        "        markers.append(marker_tensor)\n",
        "        nomarkers.append(nomarker_tensor)\n",
        "        nomarker_poss.append(nomarker_pos_tensor)\n",
        "\n",
        "    return markers, nomarkers, nomarker_poss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVtWSWMuGofS"
      },
      "source": [
        "train_dir = \"/content/drive/MyDrive/content/sgv-real-localize-siamese-4de85e91ea4f/real_data/train\"\n",
        "test_dir = \"/content/drive/MyDrive/content/sgv-real-localize-siamese-4de85e91ea4f/real_data/test\"\n",
        "# read_data(train_dir);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxRzB3wtKOxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "df5b11aa-989d-493c-99aa-320a47c5b764"
      },
      "source": [
        "train_adap_xs, train_xs, train_ys = read_data(train_dir)\n",
        "key_dataset = tf.data.Dataset.from_tensor_slices(np.arange(len(train_adap_xs)*16))\n",
        "print(train_adap_xs.shape)\n",
        "print(key_dataset.shape)\n",
        "print(key_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-865784a20507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_adap_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkey_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_adap_xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_adap_xs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQecE-NrKf_J"
      },
      "source": [
        "def get_random_data(adap_x, x, p):\n",
        "  l_obj = len(adap_x)\n",
        "  id = random.randint(0,l_obj-1)\n",
        "  l_img = len(adap_x[id])\n",
        "  img_id = random.randint(0, l_img-1)\n",
        "  x_marker = adap_x[id][img_id]\n",
        "  x_nonmarker = x[id][img_id]\n",
        "  pos = p[id][img_id]\n",
        "  return x_marker, x_nonmarker, pos\n",
        "\n",
        "get_random_data(train_adap_xs, train_xs, train_ys);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C-OA9ZMh9g9"
      },
      "source": [
        "class SiameseBlock(tf.keras.models.Model):\n",
        "  def __init__(self,input_shape):\n",
        "    super(SiameseBlock, self).__init__()\n",
        "    vgg16 = tf.keras.applications.VGG16(include_top=False, input_shape=input_shape)\n",
        "    self.siamese_block = tf.keras.Model(vgg16.input, vgg16.layers[-6].output)\n",
        "  def call(self,x):\n",
        "    y = self.siamese_block(x)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOYAsmuZtQk_"
      },
      "source": [
        "class Model(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.siamese = SiameseBlock(input_shape=(150,150,3))\n",
        "\n",
        "    self.attention_layer_1 = tf.keras.layers.Conv2D(100, 3, activation=\"relu\", padding=\"same\")\n",
        "    self.attention_layer_2 = tf.keras.layers.Conv2D(1, 1, activation=\"relu\")\n",
        "\n",
        "    self.post_attention_conv1 = tf.keras.layers.Conv2D(100, 3, activation=\"relu\", padding=\"same\")\n",
        "    self.post_attention_conv2 = tf.keras.layers.Conv2D(1, 1, activation=\"relu\")\n",
        "    \n",
        "  \n",
        "  def call(self, xoc, xo, debug=False):\n",
        "\n",
        "    twin1 = self.siamese(xoc)\n",
        "    twin2 = self.siamese(xo)\n",
        "    if debug: print(\"#1\", twin1.shape)\n",
        "    # print(t)\n",
        "\n",
        "    attention_conv = self.attention_layer_1(twin1)\n",
        "    attention_conv = self.attention_layer_2(attention_conv)\n",
        "    if debug: print(\"#attention\", attention_conv.shape)\n",
        "    pre_shape = attention_conv.shape\n",
        "    attention_conv = tf.reshape(attention_conv, shape=(xoc.shape[0],-1))\n",
        "    if debug: print(\"#flattened_attention\", attention_conv.shape)\n",
        "    attention_weights = tf.nn.softmax(attention_conv, axis=1)\n",
        "    if debug: print(\"#normalized_flatten_attention\", attention_weights.shape)\n",
        "    attention_weights = tf.reshape(attention_weights, shape=pre_shape)\n",
        "    if debug: print(\"#reshaped_back_to_original_attention\", attention_weights.shape)\n",
        "\n",
        "    twin1 = twin1*attention_weights   #this will give attention map(actually attention weights are attention map, this code line will highlight the pointed object)\n",
        "    if debug: print(\"#after_twin1_attentionmap\", twin1.shape)\n",
        "    twin1_reduced = tf.reduce_sum(twin1,axis=1,keepdims=True)\n",
        "    twin1_reduced = tf.reduce_sum(twin1_reduced,axis=2,keepdims=True)\n",
        "    if debug: print(\"#after_twin1_attentionmap_reducedto vector\", twin1_reduced.shape)\n",
        "\n",
        "    cross_correlation = twin1_reduced*twin2\n",
        "    if debug: print(\"#combination of twin2 with attention map\", cross_correlation.shape)\n",
        "    tw_shape = twin1.shape\n",
        "    # twin1 = tf.reshape(twin1, (xoc.shape[0], -1))\n",
        "    # twin2 = tf.reshape(twin2, (xoc.shape[0], -1))\n",
        "\n",
        "    # cross_correlation = tf.reshape(cross_correlation, shape=tw_shape)\n",
        "    cc2 = self.post_attention_conv1(cross_correlation)\n",
        "    if debug: print(\"#op of 1st bottlneck layer\", cc2.shape)\n",
        "    score_map = self.post_attention_conv2(cc2)\n",
        "    if debug: print(\"#Scoremap: op of 2nd bottlneck layer\", score_map.shape)\n",
        "    score_map_shape = score_map.shape\n",
        "    score_map = tf.reshape(score_map, (score_map_shape[0],-1))\n",
        "    score_map_weights = tf.nn.softmax(score_map)\n",
        "    score_map_weights = tf.reshape(score_map_weights, score_map_shape)\n",
        "#below code is to apply softargmax\n",
        "    # print(score_map_weights)\n",
        "    a = np.array([[i] for i in range(1,19)])\n",
        "    a = np.matmul(a, np.ones((1,18)))\n",
        "    # print(a.shape)\n",
        "    # print(a)\n",
        "    a_t = a.T\n",
        "    score_map_weights = tf.squeeze(score_map_weights, -1)\n",
        "    p_y = tf.reduce_sum(score_map_weights * a, axis=1)\n",
        "    p_y = tf.reduce_sum(p_y, axis=1, keepdims=True)\n",
        "    # print(p_y.shape)\n",
        "    p_x = tf.reduce_sum(score_map_weights * a_t, axis=1)\n",
        "    p_x = tf.reduce_sum(p_x, axis=1, keepdims=True)\n",
        "    # print(p_y.shape)\n",
        "    p = tf.concat([p_x, p_y], axis=-1)\n",
        "\n",
        "    return p, score_map_weights, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUcI-oM8Oel0"
      },
      "source": [
        "def load_data(key):\n",
        "  global train_adap_xs\n",
        "  global train_xs\n",
        "  global train_ys\n",
        "  l_obj = len(train_adap_xs)\n",
        "  id = random.randint(0,l_obj-1)\n",
        "  l_img = len(train_adap_xs[id])\n",
        "  img_id = random.randint(0, l_img-1)\n",
        "  x_marker = train_adap_xs[id][img_id]\n",
        "  x_nonmarker = train_xs[id][img_id]\n",
        "  pos = train_ys[id][img_id]\n",
        "  return (np.array(x_marker, dtype=np.float32)-127.5)/127.5, (np.array(x_nonmarker, dtype=np.float32)-127.5)/127.5, np.array(pos, dtype=np.float32)\n",
        "\n",
        "train_dataset = key_dataset.map(lambda key: tf.numpy_function(load_data, [key], [tf.float32, tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHR0Y9XPVi7"
      },
      "source": [
        "model = Model()\n",
        "# Building the model\n",
        "for xoc, xo, p in train_dataset.batch(batch_size=2):\n",
        "  # print(p)\n",
        "  p_hat,score,att = model(xoc, xo, debug=True)\n",
        "  # print(p_hat)\n",
        "  # print(score.shape)\n",
        "  break\n",
        "model.summary()\n",
        "model.layers[0].layers[0].summary()\n",
        "# model.layers[1].layers[1].summary()\n",
        "# model.layers[2].layers[2].summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.utils import plot_model \n",
        "# plot_model(model, 'model.png', show_shapes = True)"
      ],
      "metadata": {
        "id": "arvnLy3sTwNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VHOPLHFP51G"
      },
      "source": [
        "train_dataset_batched=train_dataset.batch(batch_size=20, drop_remainder=True)\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "loss_tracker = []\n",
        "for epoch in range(100):\n",
        "  total_loss = 0\n",
        "  for id, (xoc, xo, p) in enumerate(train_dataset_batched):\n",
        "    with tf.GradientTape() as tape:\n",
        "      p_hat,_,_ = model(xoc, xo)\n",
        "      loss = (p_hat*150/18 - p*150)**2\n",
        "      loss = tf.reduce_sum(loss, axis=-1)\n",
        "      loss = tf.reduce_mean(loss)\n",
        "    total_loss += loss.numpy().item()\n",
        "    grad = tape.gradient(loss, model.trainable_variables)\n",
        "    optim.apply_gradients(zip(grad, model.trainable_variables))\n",
        "    if id % 20 == 0:\n",
        "      print(\"Epoch {} batch {} loss {}\".format(epoch,id, loss)) \n",
        "  loss_tracker.append(total_loss/1)\n",
        "  print(\"Epoch {} total_loss {}\".format( epoch, total_loss/1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikxpyn_9caDf"
      },
      "source": [
        "plt.plot(loss_tracker)\n",
        "plt.show()\n",
        "model.save_weights(\"weights.h5\")\n",
        "model.save_weights(\"/content/drive/MyDrive/content/Attention/weights_150x150_18x18.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPrNZ8zWHH5i"
      },
      "source": [
        "# model.load_weights(\"/content/drive/MyDrive/IISc/weights_150x150_18x18.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW9RmGMMaVLF"
      },
      "source": [
        "# test_dir = \"/content/sgv-real-localize-siamese-4de85e91ea4f/real_data/test\"\n",
        "test_adap_xs, test_xs, test_ys = read_data(test_dir)\n",
        "test_key_dataset = tf.data.Dataset.from_tensor_slices(np.arange(len(test_adap_xs)*16))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRVAu7aa8TN"
      },
      "source": [
        "def load_test_data(key):\n",
        "  global test_adap_xs\n",
        "  global test_xs\n",
        "  global test_ys\n",
        "  l_obj = len(test_adap_xs)\n",
        "  id = random.randint(0,l_obj-1)\n",
        "  l_img = len(test_adap_xs[id])\n",
        "  img_id = random.randint(0, l_img-1)\n",
        "  x_marker = test_adap_xs[id][img_id]\n",
        "  x_nonmarker = test_xs[id][img_id]\n",
        "  pos = test_ys[id][img_id]\n",
        "  return (np.array(x_marker, dtype=np.float32)-127.5)/127.5, (np.array(x_nonmarker, dtype=np.float32)-127.5)/127.5, np.array(pos, dtype=np.float32)\n",
        "\n",
        "test_dataset = test_key_dataset.map(lambda key: tf.numpy_function(load_test_data, [key], [tf.float32, tf.float32, tf.float32]), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku7T7tcbbVAT"
      },
      "source": [
        "count = 0\n",
        "loss = 0\n",
        "for id, (xoc, xo, p_o) in enumerate(test_dataset.batch(1)):\n",
        "  plt.subplots(figsize=(18,8 ))\n",
        "  p,scoremap,attention_map = model(xoc,xo)\n",
        "  plt.subplot(141)\n",
        "  plt.imshow(xoc[0])\n",
        "  plt.title(\"Input\")\n",
        "  plt.subplot(142)\n",
        "  plt.imshow(attention_map[0][:,:,0], cmap=\"gray\")\n",
        "  plt.title(\"Attention Map\")\n",
        "  plt.subplot(143)\n",
        "  plt.imshow(scoremap[0], cmap=\"gray\")\n",
        "  plt.title(\"Score Map\")\n",
        "  plt.subplot(144)\n",
        "  plt.title(\"Output\")\n",
        "  plt.imshow(xo[0])\n",
        "  loss += (p/18 - p_o)**2\n",
        "  plt.scatter(p[0][0]*150/18,p[0][1]*150/18,c=\"r\",marker=\"x\")\n",
        "  plt.show()\n",
        "  count += 1\n",
        "  # break\n",
        "print(loss, count, loss/count)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}